## Скрапер и обработчик продуктов из Вкусвилл

В репозитории находится скрипт, который:
1. Собирает список товаров из выбранной **категории** Вкусвилл;
2. Скачивает сырой **HTML** каждой карточки товара;
3. Парсит страницы, извлекая цену, наличие, состав и прочие атрибуты;
4. Сохраняет результат в аккуратные **CSV-файлы**, пригодные для анализа в Excel / pandas.

Дополнительно поддерживается:
1. Работа с **куками**, чтобы видеть актуальные цены и наличие **для вашего адреса доставки**;
2. Режим обработки **одного продукта** (удобно для отладки);
3. Скрипт для оперативной **проверки наличия** товаров по списку URL-ов с учётом ваших куков;
4. И ещё пара полезных флажков на все случаи жизни.

> Проект используется в составе [MealMosaic](https://github.com/anxieuse/mealmosaic) как «мини-API» по продуктам из Вкусвилл.

---

## Установка и запуск
### Предварительные требования
• Python ≥ 3.9<br/>
• Современная Unix-подобная ОС (тестировалось на Ubuntu 22.04). Windows также должен работать в WSL.

### Клонирование и установка
```bash
# Клонировать репозиторий
git clone <repo_url>
cd <repo_name>

# Создать виртуальное окружение и установить зависимости
python3 -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# Только один раз: установить браузеры Playwright
playwright install
```

### Быстрый старт
1. **Экспорт куки (опционально, но рекомендуется):**
   ```bash
   python vkusvill.py --setup-cookies cookies.json
   ```
   Откроется окно Chrome — выберите адрес доставки, затем вернитесь в терминал и нажмите <Enter>. Куки будут сохранены в `cookies.json`.

2. **Скрапинг всей категории:**
   ```bash
   python vkusvill.py \
      --category-url "https://vkusvill.ru/goods/gotovaya-eda/" \
      --cookies cookies.json \
      --generate-urls
   ```
   HTML-страницы товаров окажутся в `data/gotovaya-eda/htmls/`, детальный дата-сет — в `data/gotovaya-eda/gotovaya-eda_detailed.csv`, а список URL-ов — в `data/gotovaya-eda/gotovaya-eda_product_urls.csv`.

3. **Скрапинг одного продукта:**
   ```bash
   python vkusvill.py --url https://vkusvill.ru/goods/moloko-3-2-1-l-173.html
   ```

4. **Проверка наличия товаров по списку:**
   ```bash
   python vkusvill.py --check-availability my_products.csv --cookies cookies.json
   ```
   CSV должен содержать колонку `url`; наличие выводится в stdout.

---

## Подробнее про флаги

| Флаг | Назначение |
|------|------------|
| `--url <PRODUCT_URL>` | Скрапинг только одного продукта и вывод JSON в терминал |
| `--category-url <CATEGORY_URL>` | Базовый URL категории для скрапинга (по умолчанию — «готовая еда») |
| `--generate-urls` | Игнорировать кэш и заново собрать список URL-ов |
| `--update-urls` | Добавить только **новые** продукты к существующему списку |
| `--force-refetch` | Перекачать HTML, даже если он уже сохранён |
| `--force-reparse` | Перепарсить **все** сохранённые HTML заново |
| `--setup-cookies <FILE>` | Захватить куки через реальный браузер и сохранить в `<FILE>` |
| `--cookies <FILE>` | Загрузить куки из файла |
| `--check-availability <CSV>` | Проверить наличие товаров из списка URL-ов |
| `--no-logging` | Отключить вывод в консоль (всё равно пишется в `vkusvill.log`) |

### Типичный workflow
1. Запустите с `--generate-urls`, когда обрабатываете категорию впервые.
2. В дальнейшем используйте `--update-urls`, чтобы добавлять только новые товары.
3. При серьёзных изменениях на сайте применяйте `--force-refetch` и/или `--force-reparse`.

---

## Структура проекта
```
.
├── vkusvill.py                              # Главный CLI: скрапинг, парсинг, экспорт CSV
├── runner.sh                                # Bash-помощник
├── data/                                    # Генерируемый вывод (по подпапке на категорию)
│   └── gotovaya-eda/
│       ├── htmls/                           # сырой HTML каждого товара
│       ├── gotovaya-eda_product_urls.csv
│       └── gotovaya-eda_detailed.csv
└── README.md                                # Вы здесь
```
